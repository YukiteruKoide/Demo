{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97095e7a-b41d-4397-9cf7-19832dc88c6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Databricks Auto Loader による新規データ取り込み\n",
    "\n",
    "このノートブックでは、Databricks Auto Loaderを使用してVolumeに配置された新規CSVファイルを自動的にトランザクションテーブルに取り込みます。\n",
    "\n",
    "## 主な機能\n",
    "- **Auto Loader**: 新規ファイルの自動検出・取り込み\n",
    "- **Schema定義**: CSVファイルの構造を事前定義\n",
    "- **データ品質管理**: NULL値の除外処理\n",
    "\n",
    "## 処理フロー\n",
    "1. Volume内の新規CSVファイルを監視\n",
    "2. 定義されたスキーマでデータを読み込み\n",
    "3. NULL値を除外してデータをクリーンアップ\n",
    "4. Deltaテーブルに追加保存\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1019adb1-c11b-411b-a764-c0fae25ae7a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Auto Loaderによるデータ取り込み処理\n",
    "\n",
    "Volume内の新規CSVファイルを監視し、自動的にトランザクションテーブルに取り込みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc81e1e7-a076-4eb6-8052-4c573b1e6301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Auto Loaderを使用してVolumeからCSVファイルを読み込み\n",
    "df = (\n",
    "  spark.readStream                      # ストリーミング読み込みを開始\n",
    "  .format(\"cloudFiles\")                 # Auto Loaderフォーマットを指定\n",
    "  .option(\"cloudFiles.format\", \"csv\")   # ソースファイル形式をCSVに設定\n",
    "  .option(\"header\", \"true\")             # ヘッダー行ありと指定\n",
    "  # CSVファイルのスキーマを事前定義（データ型を明確化）\n",
    "  .schema(\"transaction_id INT, customer_id INT, product_id INT, store_id INT, employee_id INT, quantity INT, purchase_date DATE, _rescued_data STRING\")\n",
    "  .load(\"/Volumes/users/yukiteru_koide/volume_yukiteru_mart_transaction\")  # Volumeパスを指定\n",
    "  .filter(\"transaction_id IS NOT NULL\") # データ品質管理：transaction_idがNULLのレコードを除外\n",
    ")\n",
    "\n",
    "# Deltaテーブルに書き込み\n",
    "df.writeStream.format(\"delta\") \\\n",
    "  .option(\"checkpointLocation\", \"/Volumes/users/yukiteru_koide/volume_yukiteru_mart_transaction\") \\  # チェックポイント保存場所\n",
    "  .trigger(once=True) \\                 # 一度だけ実行（バッチ処理）\n",
    "  .toTable(\"users.yukiteru_koide.transactions_table\")  # 対象Deltaテーブル\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ef09f83-77c8-4613-9f3a-424525e823e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 処理完了\n",
    "\n",
    "Auto Loaderによる新規データの取り込みが完了しました。\n",
    "\n",
    "### 処理結果の確認方法\n",
    "1. `BeforeAftter.ipynb` を使用して件数の変化を確認\n",
    "2. 取り込まれたデータの品質をチェック\n",
    "3. 必要に応じてマートテーブルを再作成\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Volume をトリガーにした Auto Loader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
