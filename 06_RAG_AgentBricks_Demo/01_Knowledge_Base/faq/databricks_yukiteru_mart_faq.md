# Databricks & Yukiteru Mart FAQ

## Databricks技術に関するFAQ

### Q1: メダリオンアーキテクチャのメリットは何ですか？
**A**: メダリオンアーキテクチャには以下のメリットがあります：
- **段階的なデータ品質向上**: Bronze→Silver→Goldの各層で品質を段階的に向上
- **データガバナンス**: 各層での役割が明確で、管理・監査が容易
- **再利用性**: Silver層のクリーンなデータを複数のGold層で活用可能
- **パフォーマンス**: 用途に応じた最適化により高速なクエリ実行
- **柔軟性**: ビジネス要件の変更に対応しやすい設計

### Q2: Auto Loaderの設定方法を教えてください
**A**: Auto Loaderの基本設定手順：
```python
# 基本的なAuto Loader設定
(spark.readStream
 .format("cloudFiles")
 .option("cloudFiles.format", "csv")  # ファイル形式
 .option("cloudFiles.schemaLocation", "/path/to/schema")  # スキーマ保存先
 .option("header", "true")
 .load("/path/to/source/")  # 監視するフォルダ
 .writeStream
 .format("delta")
 .option("checkpointLocation", "/path/to/checkpoint")  # チェックポイント
 .table("target_table")  # 出力先テーブル
)
```
重要なポイント：
- スキーマ保存先とチェックポイントの指定は必須
- 初回実行時に既存ファイルもすべて処理される
- 新しいファイルのみ自動的に検出・処理

### Q3: Delta Lakeでタイムトラベルする方法は？
**A**: Delta Lakeのタイムトラベル機能の使用方法：
```sql
-- 特定の日時のデータを参照
SELECT * FROM table_name TIMESTAMP AS OF '2024-01-15 10:30:00'

-- 特定のバージョンを参照
SELECT * FROM table_name VERSION AS OF 10

-- バージョン履歴の確認
DESCRIBE HISTORY table_name
```
活用場面：
- データの誤更新時の復旧
- 特定時点での分析・レポート作成
- A/Bテスト用のデータセット比較

### Q4: クラスターのスケーリング方法は？
**A**: Databricksクラスターのスケーリング設定：
- **Auto Scaling有効化**: クラスター設定でAuto Scalingをオン
- **最小・最大ノード数設定**: ワークロードに応じて適切な範囲を設定
- **スケールアップ条件**: CPU使用率、メモリ使用率の閾値設定
- **スケールダウン条件**: アイドル時間の設定（通常10-15分）
- **Spot Instance活用**: コスト削減のためのスポットインスタンス利用

推奨設定：
- 最小ノード数: 2
- 最大ノード数: ワークロードの3-5倍
- アイドル時間: 10分

### Q5: Unity Catalogの権限管理はどのように行いますか？
**A**: Unity Catalogの権限管理方法：
```sql
-- カタログレベルの権限付与
GRANT USE CATALOG ON CATALOG catalog_name TO `group_name`

-- スキーマレベルの権限付与
GRANT CREATE, USE SCHEMA ON SCHEMA schema_name TO `user_name`

-- テーブルレベルの権限付与
GRANT SELECT, INSERT ON TABLE table_name TO `user_name`

-- 権限の確認
SHOW GRANTS ON CATALOG catalog_name
```
権限の種類：
- **USE**: オブジェクトの参照権限
- **CREATE**: 新規オブジェクト作成権限
- **SELECT**: データ読み取り権限
- **INSERT/UPDATE/DELETE**: データ操作権限

## Yukiteru Mart ビジネスに関するFAQ

### Q6: 売上トップ10の商品は何ですか？
**A**: 2024年上半期の売上トップ10商品：
1. **プレミアム有機野菜セット** (食品・飲料) - 月平均1,200万円
2. **ワイヤレスイヤホン Pro** (家電) - 月平均980万円
3. **カジュアルジャケット** (ファッション) - 月平均850万円
4. **スマート炊飯器** (家電) - 月平均720万円
5. **オーガニック調味料セット** (食品・飲料) - 月平均680万円
6. **ビジネススーツ** (ファッション) - 月平均650万円
7. **知育玩具シリーズ** (玩具) - 月平均580万円
8. **フィットネス機器** (スポーツ) - 月平均540万円
9. **インテリア家具** (ホーム・ガーデン) - 月平均520万円
10. **ビジネス書籍** (書籍・文具) - 月平均480万円

### Q7: 新宿店の特徴を教えてください
**A**: 新宿店（フラッグシップ店）の特徴：
- **規模**: 全店舗中最大（売場面積12,000㎡）
- **営業時間**: 10:00-22:00（年中無休）
- **フロア構成**: 地下1階-地上7階
- **特別サービス**: 
  - パーソナルショッピングアドバイザー
  - 当日配送サービス
  - 多言語対応スタッフ
  - 法人向け一括購買
- **プレミアムフロア**: 6-7階は高級商品専門
- **アクセス**: JR新宿駅東口徒歩3分、地下鉄直結

### Q8: 優良顧客の特徴は？
**A**: 優良顧客（上位20%）の分析結果：
- **購買頻度**: 月3-5回の定期購入
- **平均単価**: 1回あたり8,000-15,000円
- **年齢層**: 30-50代が中心（特に35-45歳）
- **購入カテゴリ**: 食品・家電・ファッションをバランスよく購入
- **メンバーシップ**: プレミアム会員が80%以上
- **購入傾向**: 
  - 品質重視（価格より品質を優先）
  - 新商品への関心が高い
  - オンライン・オフライン両方を活用
  - ギフト需要も多い

### Q9: 季節性のある商品カテゴリは？
**A**: 季節別の売上変動パターン：

**春（3-5月）**:
- 家電・家具: 新生活需要で売上150%増
- ガーデニング用品: 園芸シーズンで売上200%増
- ファッション: 春物商品で売上120%増

**夏（6-8月）**:
- 冷房・扇風機: 暑さ対策で売上300%増
- アウトドア用品: レジャーシーズンで売上180%増
- 浴衣・祭り用品: イベント需要で売上250%増

**秋（9-11月）**:
- 書籍: 読書週間で売上130%増
- 防寒用品: 冬支度で売上160%増
- ハロウィン用品: 期間限定で売上400%増

**冬（12-2月）**:
- ギフト商品: クリスマス・お正月で売上200%増
- 暖房器具: 寒さ対策で売上250%増
- チョコレート: バレンタインで売上300%増

### Q10: Databricksでエラーが出た時の対処法は？
**A**: よくあるエラーと対処法：

**1. クラスター接続エラー**
- 原因: クラスターが停止している
- 対処: クラスターを再起動、または新しいクラスターにアタッチ

**2. メモリ不足エラー**
- 原因: データサイズがクラスター容量を超過
- 対処: クラスターのスケールアップ、またはデータの分割処理

**3. 権限エラー**
- 原因: Unity Catalogの権限不足
- 対処: 管理者に権限付与を依頼、または適切なカタログ・スキーマに切り替え

**4. スキーマエラー**
- 原因: データ型の不一致
- 対処: スキーマの明示的指定、またはinferSchemaオプションの使用

**5. ファイルパスエラー**
- 原因: ファイルパスが存在しない
- 対処: パスの確認、Volumeパスの使用

### Q11: ダッシュボードの作り方は？
**A**: Databricksダッシュボード作成手順：

**1. SQLクエリの準備**
```sql
-- 例: 月次売上サマリー
SELECT 
  DATE_TRUNC('month', transaction_date) as month,
  store_name,
  SUM(amount) as total_sales
FROM gold.monthly_sales_summary
GROUP BY month, store_name
ORDER BY month DESC, total_sales DESC
```

**2. 可視化の作成**
- クエリ実行後、「Add visualization」をクリック
- グラフの種類を選択（棒グラフ、線グラフ、円グラフ等）
- X軸、Y軸、グループ化の設定

**3. ダッシュボードの作成**
- 「Create Dashboard」を選択
- 複数の可視化を組み合わせ
- フィルター機能の追加

**4. 共有・更新設定**
- 共有権限の設定
- 自動更新スケジュールの設定
- アラート機能の設定

### Q12: データをCSVで出力する方法は？
**A**: Databricksからデータを出力する方法：

**1. ノートブックから直接ダウンロード**
```python
# DataFrameをPandasに変換してダウンロード
df = spark.table("table_name").toPandas()
df.to_csv("/dbfs/tmp/output.csv", index=False)

# ファイルをローカルにダウンロード
dbutils.fs.cp("/dbfs/tmp/output.csv", "file:/tmp/output.csv")
```

**2. Volumeを使用した出力**
```python
# Volumeに出力
df.coalesce(1).write.mode("overwrite").option("header", "true").csv("/Volumes/catalog/schema/volume/output/")
```

**3. SQLでの出力**
```sql
-- テーブルからCSV出力
COPY (SELECT * FROM table_name) TO '/Volumes/catalog/schema/volume/output.csv'
OPTIONS (FORMAT CSV, HEADER true)
```

## トラブルシューティング

### Q13: パフォーマンスが遅い時の対処法は？
**A**: パフォーマンス改善の手順：

**1. クエリの最適化**
- 不要な列の除外（SELECT *の回避）
- 適切なフィルター条件の追加
- JOINの順序最適化

**2. Deltaテーブルの最適化**
```sql
-- ファイル最適化
OPTIMIZE table_name

-- Z-Order最適化
OPTIMIZE table_name ZORDER BY (column_name)

-- 統計情報の更新
ANALYZE TABLE table_name COMPUTE STATISTICS
```

**3. クラスター設定の見直し**
- ノード数の増加
- Photon Engineの有効化
- 適切なインスタンスタイプの選択

### Q14: データが更新されない時は？
**A**: データ更新の確認手順：
1. **Auto Loaderの状態確認**: チェックポイント情報の確認
2. **スキーマ進化の確認**: 新しい列が追加された場合の対応
3. **権限の確認**: 書き込み権限の有無
4. **ストリーミングジョブの状態**: 実行状況の確認
5. **ファイル配置の確認**: 正しいパスへのファイル配置

### Q15: コストを削減する方法は？
**A**: コスト削減の施策：
- **Spot Instanceの活用**: 開発・テスト環境での利用
- **Auto Terminationの設定**: 未使用クラスターの自動停止
- **適切なクラスターサイズ**: ワークロードに応じたサイジング
- **データの圧縮**: Delta Lakeの圧縮機能活用
- **Photon Engineの活用**: 処理時間短縮によるコスト削減

---

追加の質問がございましたら、各店舗スタッフまたは技術サポートチームまでお気軽にお問い合わせください。 