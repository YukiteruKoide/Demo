# Databricks Demo Collection ğŸš€

## æ¦‚è¦
ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€Databricksãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æ´»ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŠã‚ˆã³ãƒ‡ãƒ¼ã‚¿åˆ†æã®ãƒ‡ãƒ¢ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé›†ã§ã™ã€‚åˆå¿ƒè€…å‘ã‘ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‹ã‚‰å®Ÿè·µçš„ãªETLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¾ã§ã€æ®µéšçš„ã«å­¦ç¿’ã§ãã‚‹æ§‹æˆã«ãªã£ã¦ã„ã¾ã™ã€‚

## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

### ğŸ“Š [01_yukiteru_mart](./01_yukiteru_mart/) - ãƒ‡ãƒ¼ã‚¿åˆ†æåŸºç¤
**ãƒ¬ãƒ™ãƒ«**: åˆç´šã€œä¸­ç´š | **æ‰€è¦æ™‚é–“**: 2-3æ™‚é–“

Yukiteru Martã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸåŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

**å­¦ç¿’å†…å®¹:**
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã®è¨­å®šï¼ˆä¸»ã‚­ãƒ¼ãƒ»å¤–éƒ¨ã‚­ãƒ¼ï¼‰
- åˆ†æç”¨ãƒãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
- Auto Loaderã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿
- åŸºæœ¬çš„ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:**
- Databricks SQL
- Delta Lake
- Auto Loader
- Databricks ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©³ç´°æ§‹æˆ:**

#### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
**ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–¢ä¿‚**:
- **Customers**: é¡§å®¢ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸»ã‚­ãƒ¼: customer_idï¼‰
- **Products**: å•†å“ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸»ã‚­ãƒ¼: product_idï¼‰
- **Stores**: åº—èˆ—ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸»ã‚­ãƒ¼: store_idï¼‰
- **Inventory**: åœ¨åº«ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆè¤‡åˆã‚­ãƒ¼: store_id + product_idï¼‰
- **Transactions**: å–å¼•ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸»ã‚­ãƒ¼: transaction_idï¼‰

#### ğŸ“ [01_äº‹å‰ä½œæ¥­.ipynb] - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã¨ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ
**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºä¿ã®ãŸã‚ã®åŸºç›¤æ§‹ç¯‰
**å®Ÿè£…å†…å®¹**:

**1. ä¸»ã‚­ãƒ¼åˆ¶ç´„ã®è¨­å®š**:
```sql
-- é¡§å®¢ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¸»ã‚­ãƒ¼è¨­å®š
ALTER TABLE customers 
ADD CONSTRAINT pk_customers PRIMARY KEY (customer_id);

-- å•†å“ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¸»ã‚­ãƒ¼è¨­å®š
ALTER TABLE products 
ADD CONSTRAINT pk_products PRIMARY KEY (product_id);

-- åº—èˆ—ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¸»ã‚­ãƒ¼è¨­å®š
ALTER TABLE stores 
ADD CONSTRAINT pk_stores PRIMARY KEY (store_id);
```

**2. å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®å®Ÿè£…**:
```sql
-- å–å¼•ãƒ†ãƒ¼ãƒ–ãƒ«ã®å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„
ALTER TABLE transactions 
ADD CONSTRAINT fk_transactions_customer 
FOREIGN KEY (customer_id) REFERENCES customers(customer_id);

ALTER TABLE transactions 
ADD CONSTRAINT fk_transactions_product 
FOREIGN KEY (product_id) REFERENCES products(product_id);

ALTER TABLE transactions 
ADD CONSTRAINT fk_transactions_store 
FOREIGN KEY (store_id) REFERENCES stores(store_id);

-- åœ¨åº«ãƒ†ãƒ¼ãƒ–ãƒ«ã®å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„
ALTER TABLE inventory 
ADD CONSTRAINT fk_inventory_product 
FOREIGN KEY (product_id) REFERENCES products(product_id);

ALTER TABLE inventory 
ADD CONSTRAINT fk_inventory_store 
FOREIGN KEY (store_id) REFERENCES stores(store_id);
```

**3. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯**:
```sql
-- å­¤ç«‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ¤œå‡º
SELECT COUNT(*) as orphaned_transactions
FROM transactions t
LEFT JOIN customers c ON t.customer_id = c.customer_id
WHERE c.customer_id IS NULL;

-- å‚ç…§æ•´åˆæ€§ã®æ¤œè¨¼
SELECT 
  'transactions->customers' as reference_check,
  COUNT(DISTINCT t.customer_id) as referenced_customers,
  COUNT(DISTINCT c.customer_id) as available_customers
FROM transactions t
LEFT JOIN customers c ON t.customer_id = c.customer_id;
```

#### ğŸª [02_ãƒãƒ¼ãƒˆä½œæˆ.ipynb] - åˆ†æç”¨ãƒãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰
**ç›®çš„**: ãƒ“ã‚¸ãƒã‚¹åˆ†æã«æœ€é©åŒ–ã•ã‚ŒãŸé›†è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ

**1. é¡§å®¢åˆ†æãƒãƒ¼ãƒˆ (customer_summary_mart)**:
```sql
CREATE OR REPLACE TABLE customer_summary_mart AS
SELECT 
  c.customer_id,
  c.customer_name,
  c.age,
  c.gender,
  c.membership_level,
  -- è³¼è²·è¡Œå‹•æŒ‡æ¨™
  COUNT(DISTINCT t.transaction_id) as total_transactions,
  COUNT(DISTINCT DATE(t.transaction_date)) as visit_days,
  SUM(t.quantity * p.unit_price) as total_spent,
  AVG(t.quantity * p.unit_price) as avg_transaction_value,
  MAX(t.transaction_date) as last_purchase_date,
  MIN(t.transaction_date) as first_purchase_date,
  DATEDIFF(MAX(t.transaction_date), MIN(t.transaction_date)) as customer_lifetime_days,
  
  -- å•†å“å—œå¥½åˆ†æ
  MODE(p.category) as favorite_category,
  COUNT(DISTINCT p.product_id) as unique_products_purchased,
  
  -- åº—èˆ—åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
  MODE(s.store_name) as most_visited_store,
  COUNT(DISTINCT s.store_id) as stores_visited,
  
  -- é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†é¡
  CASE 
    WHEN SUM(t.quantity * p.unit_price) >= 50000 THEN 'VIP'
    WHEN SUM(t.quantity * p.unit_price) >= 20000 THEN 'å„ªè‰¯'
    WHEN SUM(t.quantity * p.unit_price) >= 5000 THEN 'ä¸€èˆ¬'
    ELSE 'æ–°è¦ãƒ»ä½é »åº¦'
  END as customer_segment,
  
  -- è³¼è²·é »åº¦è©•ä¾¡
  ROUND(COUNT(DISTINCT t.transaction_id) * 1.0 / 
        NULLIF(DATEDIFF(MAX(t.transaction_date), MIN(t.transaction_date)), 0) * 30, 2) 
        as monthly_purchase_frequency
        
FROM customers c
LEFT JOIN transactions t ON c.customer_id = t.customer_id
LEFT JOIN products p ON t.product_id = p.product_id
LEFT JOIN stores s ON t.store_id = s.store_id
GROUP BY c.customer_id, c.customer_name, c.age, c.gender, c.membership_level
```

**2. åº—èˆ—å£²ä¸Šåˆ†æãƒãƒ¼ãƒˆ (store_sales_summary_mart)**:
```sql
CREATE OR REPLACE TABLE store_sales_summary_mart AS
SELECT 
  s.store_id,
  s.store_name,
  s.location,
  s.manager_name,
  s.opening_hours,
  
  -- å£²ä¸Šå®Ÿç¸¾æŒ‡æ¨™
  COUNT(DISTINCT t.transaction_id) as total_transactions,
  COUNT(DISTINCT t.customer_id) as unique_customers,
  COUNT(DISTINCT DATE(t.transaction_date)) as operating_days,
  SUM(t.quantity * p.unit_price) as total_revenue,
  AVG(t.quantity * p.unit_price) as avg_transaction_value,
  SUM(t.quantity) as total_items_sold,
  
  -- åŠ¹ç‡æ€§æŒ‡æ¨™
  ROUND(SUM(t.quantity * p.unit_price) / COUNT(DISTINCT DATE(t.transaction_date)), 2) 
    as daily_average_revenue,
  ROUND(COUNT(DISTINCT t.customer_id) * 1.0 / COUNT(DISTINCT DATE(t.transaction_date)), 2) 
    as daily_customer_traffic,
  ROUND(SUM(t.quantity * p.unit_price) / COUNT(DISTINCT t.customer_id), 2) 
    as revenue_per_customer,
    
  -- å•†å“æ§‹æˆåˆ†æ
  COUNT(DISTINCT p.product_id) as products_sold,
  MODE(p.category) as top_selling_category,
  
  -- æ™‚é–“å¸¯åˆ†æ
  MODE(HOUR(t.transaction_date)) as peak_hour,
  COUNT(CASE WHEN HOUR(t.transaction_date) BETWEEN 9 AND 12 THEN 1 END) as morning_transactions,
  COUNT(CASE WHEN HOUR(t.transaction_date) BETWEEN 12 AND 17 THEN 1 END) as afternoon_transactions,
  COUNT(CASE WHEN HOUR(t.transaction_date) BETWEEN 17 AND 21 THEN 1 END) as evening_transactions,
  
  -- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
  CASE 
    WHEN SUM(t.quantity * p.unit_price) >= 100000 THEN 'é«˜åç›Šåº—èˆ—'
    WHEN SUM(t.quantity * p.unit_price) >= 50000 THEN 'æ¨™æº–åº—èˆ—'
    ELSE 'æ”¹å–„å¿…è¦åº—èˆ—'
  END as performance_category

FROM stores s
LEFT JOIN transactions t ON s.store_id = t.store_id
LEFT JOIN products p ON t.product_id = p.product_id
GROUP BY s.store_id, s.store_name, s.location, s.manager_name, s.opening_hours
```

**3. å•†å“åˆ†æãƒãƒ¼ãƒˆ (product_analysis_mart)**:
```sql
CREATE OR REPLACE TABLE product_analysis_mart AS
SELECT 
  p.product_id,
  p.product_name,
  p.category,
  p.unit_price,
  
  -- å£²ä¸Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
  COUNT(DISTINCT t.transaction_id) as times_sold,
  SUM(t.quantity) as total_quantity_sold,
  SUM(t.quantity * p.unit_price) as total_revenue,
  AVG(i.quantity_on_hand) as avg_inventory_level,
  
  -- åœ¨åº«åŠ¹ç‡æ€§
  ROUND(SUM(t.quantity) * 1.0 / NULLIF(AVG(i.quantity_on_hand), 0), 2) as inventory_turnover_ratio,
  
  -- åº—èˆ—é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
  COUNT(DISTINCT t.store_id) as sold_in_stores,
  MODE(s.store_name) as best_performing_store,
  
  -- é¡§å®¢å—œå¥½
  COUNT(DISTINCT t.customer_id) as unique_buyers,
  ROUND(SUM(t.quantity) * 1.0 / COUNT(DISTINCT t.customer_id), 2) as avg_quantity_per_customer
  
FROM products p
LEFT JOIN transactions t ON p.product_id = t.product_id
LEFT JOIN inventory i ON p.product_id = i.product_id
LEFT JOIN stores s ON t.store_id = s.store_id
GROUP BY p.product_id, p.product_name, p.category, p.unit_price
```

#### ğŸ”„ Auto Loader ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…
**å®Ÿè£…ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: `ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³/`

**1. [BeforeAfter.ipynb] - ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼**:
```python
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†å‰å¾Œã®ä»¶æ•°ãƒã‚§ãƒƒã‚¯
def validate_data_integrity():
    # å‡¦ç†å‰ãƒ‡ãƒ¼ã‚¿ä»¶æ•°
    before_counts = {
        'customers': spark.table('customers').count(),
        'products': spark.table('products').count(),
        'transactions': spark.table('transactions').count()
    }
    
    # ãƒãƒ¼ãƒˆä½œæˆå¾Œã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    after_counts = {
        'customer_mart': spark.table('customer_summary_mart').count(),
        'store_mart': spark.table('store_sales_summary_mart').count(),
        'product_mart': spark.table('product_analysis_mart').count()
    }
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    quality_report = spark.sql("""
        SELECT 
          'ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯' as check_type,
          CASE 
            WHEN customer_count = customer_mart_count THEN 'OK'
            ELSE 'ERROR'
          END as customer_data_integrity,
          CASE 
            WHEN total_transactions = sum_mart_transactions THEN 'OK'
            ELSE 'ERROR'
          END as transaction_data_integrity
        FROM (
          SELECT 
            (SELECT COUNT(*) FROM customers) as customer_count,
            (SELECT COUNT(*) FROM customer_summary_mart) as customer_mart_count,
            (SELECT SUM(total_transactions) FROM customer_summary_mart) as sum_mart_transactions,
            (SELECT COUNT(*) FROM transactions) as total_transactions
        )
    """)
    
    return quality_report
```

**2. [Volume ã‚’ãƒˆãƒªã‚¬ãƒ¼ã«ã—ãŸ Auto Loader.ipynb] - è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿**:
```python
# Auto Loaderè¨­å®š
def setup_auto_loader():
    # æ–°ç€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›£è¦–è¨­å®š
    auto_loader_stream = (spark.readStream
        .format("cloudFiles")
        .option("cloudFiles.format", "csv")
        .option("cloudFiles.schemaLocation", "/databricks/schemas/new_transactions")
        .option("cloudFiles.inferColumnTypes", "true")
        .option("cloudFiles.rescuedDataColumn", "_rescued_data")
        .load("/databricks/datasets/yukiteru_mart/new_data/")
    )
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã¨ãƒãƒ¼ãƒˆæ›´æ–°
    def process_new_transactions(batch_df, batch_id):
        # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        cleaned_df = batch_df.filter(col("_rescued_data").isNull())
        
        # æ—¢å­˜ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¿½åŠ 
        cleaned_df.write.format("delta").mode("append").saveAsTable("transactions")
        
        # ãƒãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®å¢—åˆ†æ›´æ–°
        update_customer_mart(batch_df)
        update_store_mart(batch_df)
        
        print(f"Batch {batch_id}: {batch_df.count()} records processed")
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†é–‹å§‹
    query = (auto_loader_stream.writeStream
        .foreachBatch(process_new_transactions)
        .option("checkpointLocation", "/databricks/checkpoints/auto_loader")
        .trigger(availableNow=True)
        .start()
    )
    
    return query

# ãƒãƒ¼ãƒˆå¢—åˆ†æ›´æ–°é–¢æ•°
def update_customer_mart(new_transactions_df):
    # å½±éŸ¿ã‚’å—ã‘ã‚‹é¡§å®¢ã®ã¿å†è¨ˆç®—
    affected_customers = new_transactions_df.select("customer_id").distinct()
    
    # éƒ¨åˆ†æ›´æ–°ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
    spark.sql("""
        MERGE INTO customer_summary_mart target
        USING (
            SELECT customer_id, ... -- å†è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
            FROM customers c
            JOIN transactions t ON c.customer_id = t.customer_id
            WHERE c.customer_id IN (SELECT customer_id FROM affected_customers_temp)
            GROUP BY c.customer_id, ...
        ) source
        ON target.customer_id = source.customer_id
        WHEN MATCHED THEN UPDATE SET *
        WHEN NOT MATCHED THEN INSERT *
    """)
```

#### ğŸ“Š [yukiteru_martãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰.lvdash.json] - ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹
**å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½**:

**1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼**:
- ç·å£²ä¸Šãƒ»é¡§å®¢æ•°ãƒ»å–å¼•æ•°ã®KPIè¡¨ç¤º
- å‰æœˆæ¯”æˆé•·ç‡ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
- åº—èˆ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°

**2. é¡§å®¢åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**:
- é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒå††ã‚°ãƒ©ãƒ•
- å¹´é½¢å±¤åˆ¥è³¼è²·ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
- ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«åˆ¥å£²ä¸Šè²¢çŒ®åº¦
- é¡§å®¢ãƒ©ã‚¤ãƒ•ã‚¿ã‚¤ãƒ ãƒãƒªãƒ¥ãƒ¼åˆ†å¸ƒ

**3. åº—èˆ—é‹å–¶ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**:
- åº—èˆ—åˆ¥å£²ä¸Šæ¯”è¼ƒæ£’ã‚°ãƒ©ãƒ•
- åœ°åŸŸåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒƒãƒ—
- æ™‚é–“å¸¯åˆ¥å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
- åº—èˆ—åŠ¹ç‡æ€§æŒ‡æ¨™ï¼ˆå®¢å˜ä¾¡ã€å®¢æ•°ç­‰ï¼‰

**4. å•†å“ãƒ»åœ¨åº«åˆ†æ**:
- å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šæ§‹æˆ
- åœ¨åº«å›è»¢ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
- å­£ç¯€æ€§å•†å“ã®éœ€è¦å¤‰å‹•
- ABCåˆ†æã«ã‚ˆã‚‹å•†å“åˆ†é¡

#### ğŸ¯ ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

**1. ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³æ„æ€æ±ºå®šæ”¯æ´**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å£²ä¸Šç›£è¦–ã«ã‚ˆã‚‹è¿…é€ŸãªçµŒå–¶åˆ¤æ–­
- åº—èˆ—é–“ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã«ã‚ˆã‚‹æ”¹å–„æ©Ÿä¼šç‰¹å®š
- é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ç«‹æ¡ˆ

**2. é‹å–¶åŠ¹ç‡åŒ–**:
- åœ¨åº«æœ€é©åŒ–ã«ã‚ˆã‚‹æ©Ÿä¼šæå¤±å‰Šæ¸›
- åº—èˆ—ã‚¹ã‚¿ãƒƒãƒ•é…ç½®æœ€é©åŒ–
- å•†å“é™³åˆ—ãƒ»ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœæ¸¬å®š

**3. é¡§å®¢ä½“é¨“å‘ä¸Š**:
- å€‹äººåŒ–æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ ã®åŸºç›¤ãƒ‡ãƒ¼ã‚¿
- é¡§å®¢æº€è¶³åº¦å‘ä¸Šæ–½ç­–ã®åŠ¹æœæ¸¬å®š
- ãƒãƒ£ãƒ¼ãƒ³äºˆæ¸¬ã«ã‚ˆã‚‹é¡§å®¢ç¶­æŒæ–½ç­–

**4. ãƒ‡ãƒ¼ã‚¿ã‚¬ãƒãƒŠãƒ³ã‚¹**:
- ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã¨ã‚¨ãƒ©ãƒ¼æ¤œå‡º
- å‚ç…§æ•´åˆæ€§ã«ã‚ˆã‚‹ä¿¡é ¼æ€§ç¢ºä¿
- ç›£æŸ»è¨¼è·¡ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å¯¾å¿œ

### ğŸ”„ [02_yukiterumart_ETL](./02_yukiterumart_ETL/) - ãƒ¡ãƒ€ãƒªã‚ªãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ETL
**ãƒ¬ãƒ™ãƒ«**: ä¸­ç´šã€œä¸Šç´š | **æ‰€è¦æ™‚é–“**: 4-6æ™‚é–“

æœ¬æ ¼çš„ãªETLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ¡ãƒ€ãƒªã‚ªãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§æ§‹ç¯‰

**å­¦ç¿’å†…å®¹:**
- Bronze/Silver/Goldãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è¨­è¨ˆãƒ»å®Ÿè£…
- å¢—åˆ†ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨MERGE INTO
- ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†
- ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹å‘ã‘é›†è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:**
- Databricks Runtime
- Delta Lake (ACID, Time Travel)
- Auto Loader
- PySpark
- Databricks Workflows

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©³ç´°æ§‹æˆ:**

#### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
- **customers.csv**: é¡§å®¢ãƒã‚¹ã‚¿ï¼ˆIDã€åå‰ã€å¹´é½¢ã€æ€§åˆ¥ã€ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—ç­‰ï¼‰
- **products.csv**: å•†å“ãƒã‚¹ã‚¿ï¼ˆIDã€åå‰ã€ã‚«ãƒ†ã‚´ãƒªã€ä¾¡æ ¼ã€åœ¨åº«ç­‰ï¼‰
- **stores.csv**: åº—èˆ—ãƒã‚¹ã‚¿ï¼ˆIDã€åå‰ã€ç«‹åœ°ã€ç®¡ç†è€…ã€å–¶æ¥­æ™‚é–“ç­‰ï¼‰
- **transactions.csv**: å–å¼•ãƒ‡ãƒ¼ã‚¿ï¼ˆå–å¼•IDã€é¡§å®¢ãƒ»å•†å“ãƒ»åº—èˆ—IDã€æ•°é‡ã€æ—¥æ™‚ç­‰ï¼‰
- **reviews.csv**: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå•†å“IDã€è©•ä¾¡ã€ã‚³ãƒ¡ãƒ³ãƒˆç­‰ï¼‰
- **new_transactions_july2025.csv**: å¢—åˆ†ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–°ç€å–å¼•ï¼‰

#### ğŸ¥‰ Bronze Layer - ç”Ÿãƒ‡ãƒ¼ã‚¿æ ¼ç´å±¤
**ç›®çš„**: å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€å°é™ã®å¤‰æ›ã§Deltaå½¢å¼ã«ä¿å­˜
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `01_csv_to_bronze.ipynb`
**ä¸»è¦æ©Ÿèƒ½**:
- CSVã‹ã‚‰Delta Tableã¸ã®ä¸€æ‹¬å¤‰æ›
- ã‚¹ã‚­ãƒ¼ãƒè‡ªå‹•æ¨è«–ã¨ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ ã€ç›£æŸ»ã‚«ãƒ©ãƒ è¿½åŠ ï¼ˆä½œæˆæ—¥æ™‚ç­‰ï¼‰
- ãƒ‡ãƒ¼ã‚¿ãƒªãƒãƒ¼ã‚¸ã®ç¢ºç«‹

**æŠ€è¡“çš„ç‰¹å¾´**:
```python
# Auto Loaderè¨­å®šä¾‹
.option("cloudFiles.format", "csv")
.option("cloudFiles.schemaLocation", schema_path)
.option("cloudFiles.inferColumnTypes", "true")
```

#### ğŸ¥ˆ Silver Layer - æ´—æµ„ãƒ»çµ±åˆå±¤
**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Šã¨ãƒ†ãƒ¼ãƒ–ãƒ«é–“çµåˆã®æº–å‚™
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `02_bronz_to_sliver.ipynb`
**ä¸»è¦æ©Ÿèƒ½**:
- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼ˆNULLå€¤å‡¦ç†ã€é‡è¤‡é™¤å»ã€ç•°å¸¸å€¤æ¤œå‡ºï¼‰
- ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã¨æ¨™æº–åŒ–
- ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã®é©ç”¨
- å‚ç…§æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- ãƒ†ãƒ¼ãƒ–ãƒ«é–“ã®æ­£è¦åŒ–ãƒ»éæ­£è¦åŒ–

**ãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¾‹**:
```sql
-- é¡§å®¢å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
CASE 
  WHEN age < 25 THEN 'è‹¥å¹´å±¤'
  WHEN age < 45 THEN 'ä¸­å¹´å±¤'
  WHEN age < 65 THEN 'å£®å¹´å±¤'
  ELSE 'ã‚·ãƒ‹ã‚¢å±¤'
END as age_group

-- å–å¼•é‡‘é¡è¨ˆç®—
quantity * unit_price as total_amount
```

#### ğŸ¥‡ Gold Layer - ãƒ“ã‚¸ãƒã‚¹åˆ†æå±¤
**ç›®çš„**: ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«ç‰¹åŒ–ã—ãŸåˆ†æç”¨ãƒ†ãƒ¼ãƒ–ãƒ«
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `03_bronze_to_gold_1.ipynb`, `03_bronze_to_gold_2.ipynb`, `03_bronze_to_gold_3.ipynb`

**Gold 1 - æœˆæ¬¡å£²ä¸Šã‚µãƒãƒªãƒ¼**:
```sql
-- æœˆæ¬¡ãƒ»åº—èˆ—ãƒ»å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šé›†è¨ˆ
CREATE OR REPLACE TABLE gold.monthly_sales_summary AS
SELECT 
  year_month,
  store_name,
  product_category,
  COUNT(DISTINCT transaction_id) as transaction_count,
  SUM(total_amount) as total_revenue,
  AVG(total_amount) as avg_transaction_value,
  COUNT(DISTINCT customer_id) as unique_customers
FROM silver.transactions_detailed
GROUP BY year_month, store_name, product_category
```

**Gold 2 - é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ**:
```sql
-- RFMåˆ†æã«ã‚ˆã‚‹é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
CREATE OR REPLACE TABLE gold.customer_segments AS
SELECT 
  customer_id,
  recency_score, frequency_score, monetary_score,
  CASE 
    WHEN rfm_score >= 9 THEN 'VIPé¡§å®¢'
    WHEN rfm_score >= 7 THEN 'å„ªè‰¯é¡§å®¢'
    WHEN rfm_score >= 5 THEN 'ä¸€èˆ¬é¡§å®¢'
    ELSE 'ä¼‘çœ é¡§å®¢'
  END as customer_segment
FROM (
  SELECT *,
    recency_score + frequency_score + monetary_score as rfm_score
  FROM silver.customer_rfm_base
)
```

**Gold 3 - å•†å“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ**:
```sql
-- å•†å“å£²ä¸Š vs ãƒ¬ãƒ“ãƒ¥ãƒ¼è©•ä¾¡åˆ†æ
CREATE OR REPLACE TABLE gold.product_performance AS
SELECT 
  p.product_name,
  p.category,
  SUM(t.total_amount) as total_sales,
  COUNT(t.transaction_id) as sales_count,
  AVG(r.rating) as avg_rating,
  COUNT(r.review_id) as review_count,
  -- å£²ä¸Šãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ¯”ç‡
  ROUND(SUM(t.total_amount) / NULLIF(AVG(r.rating), 0), 2) as sales_per_rating
FROM silver.products p
LEFT JOIN silver.transactions t ON p.product_id = t.product_id
LEFT JOIN silver.reviews r ON p.product_id = r.product_id
GROUP BY p.product_id, p.product_name, p.category
```

#### ğŸ”„ å¢—åˆ†ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
**ç›®çš„**: æ–°ç€ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªå‡¦ç†ã¨ãƒãƒ¼ãƒˆæ›´æ–°
**å®Ÿè£…ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: `02_ãƒ‡ãƒ¼ã‚¿è¿½åŠ /`

**Auto Loader ã«ã‚ˆã‚‹æ–°è¦ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿** (`01_Bronze: Auto Loader ã«ã‚ˆã‚‹æ–°è¦CSVè‡ªå‹•å–ã‚Šè¾¼ã¿.ipynb`):
```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å–ã‚Šè¾¼ã¿è¨­å®š
bronze_stream = (spark.readStream
  .format("cloudFiles")
  .option("cloudFiles.format", "csv")
  .option("cloudFiles.schemaLocation", checkpoint_path)
  .option("cloudFiles.useStrictMode", "true")
  .load(source_path)
)

# Bronze ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æ›¸ãè¾¼ã¿
bronze_query = (bronze_stream.writeStream
  .format("delta")
  .outputMode("append")
  .option("checkpointLocation", checkpoint_path)
  .trigger(availableNow=True)
  .table("bronze.new_transactions")
)
```

**Silver Layer å¢—åˆ†å¤‰æ›** (`02_Silver: æ–°ç€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¤‰æ›ãƒ»çµåˆ.ipynb`):
```sql
-- MERGE INTO ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªæ›´æ–°
MERGE INTO silver.transactions_detailed as target
USING (
  SELECT 
    t.*, c.customer_name, p.product_name, s.store_name,
    t.quantity * p.unit_price as total_amount
  FROM bronze.new_transactions t
  JOIN silver.customers c ON t.customer_id = c.customer_id
  JOIN silver.products p ON t.product_id = p.product_id
  JOIN silver.stores s ON t.store_id = s.store_id
  WHERE t.processed_flag = 0
) as source
ON target.transaction_id = source.transaction_id
WHEN NOT MATCHED THEN INSERT *
```

**Gold Layer å†é›†è¨ˆ** (`03_Gold: Silverå…¨ä½“ã‹ã‚‰å†é›†è¨ˆ.ipynb`):
- æœˆæ¬¡å£²ä¸Šã‚µãƒãƒªãƒ¼ã®å·®åˆ†æ›´æ–°
- é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å†è¨ˆç®—
- å•†å“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®æ›´æ–°
- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç”Ÿæˆ

#### ğŸ“Š å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹åˆ†ææ©Ÿèƒ½

**1. å£²ä¸Šåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**:
- æ™‚ç³»åˆ—å£²ä¸Šæ¨ç§»ï¼ˆæ—¥æ¬¡ãƒ»æœˆæ¬¡ãƒ»å››åŠæœŸï¼‰
- åº—èˆ—é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
- å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šæ§‹æˆ
- å­£ç¯€æ€§ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ

**2. é¡§å®¢åˆ†æ**:
- RFMåˆ†æã«ã‚ˆã‚‹é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- é¡§å®¢ãƒ©ã‚¤ãƒ•ã‚¿ã‚¤ãƒ ãƒãƒªãƒ¥ãƒ¼ï¼ˆCLVï¼‰ç®—å‡º
- ãƒãƒ£ãƒ¼ãƒ³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ç”¨ç‰¹å¾´é‡
- è³¼è²·è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ

**3. å•†å“ãƒ»åœ¨åº«åˆ†æ**:
- å•†å“å›è»¢ç‡ã¨åœ¨åº«æœ€é©åŒ–
- å£²ä¸Š vs ãƒ¬ãƒ“ãƒ¥ãƒ¼è©•ä¾¡ã®ç›¸é–¢åˆ†æ
- ABCåˆ†æã«ã‚ˆã‚‹å•†å“åˆ†é¡
- å­£ç¯€æ€§å•†å“ã®éœ€è¦äºˆæ¸¬

**4. åº—èˆ—é‹å–¶åˆ†æ**:
- åº—èˆ—ç«‹åœ°åŠ¹æœã®æ¸¬å®š
- ã‚¹ã‚¿ãƒƒãƒ•ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
- å–¶æ¥­æ™‚é–“åˆ¥å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³
- åœ°åŸŸåˆ¥å¸‚å ´ç‰¹æ€§åˆ†æ

#### ğŸ¯ ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†
**å®Ÿè£…æ©Ÿèƒ½**:
- ã‚¹ã‚­ãƒ¼ãƒé€²åŒ–ã®è‡ªå‹•æ¤œå‡ºã¨å¯¾å¿œ
- ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¨ç•°å¸¸æ¤œå‡º
- å‚ç…§æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«é•åã®æ¤œå‡ºã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
- ãƒ‡ãƒ¼ã‚¿ãƒªãƒãƒ¼ã‚¸ã®å¯è¦–åŒ–

**å“è³ªãƒã‚§ãƒƒã‚¯ä¾‹**:
```sql
-- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚¯ã‚¨ãƒªä¾‹
CREATE OR REPLACE VIEW data_quality.transaction_checks AS
SELECT 
  'transactions' as table_name,
  COUNT(*) as total_records,
  COUNT(*) - COUNT(customer_id) as null_customer_ids,
  COUNT(*) - COUNT(product_id) as null_product_ids,
  SUM(CASE WHEN quantity <= 0 THEN 1 ELSE 0 END) as invalid_quantities,
  SUM(CASE WHEN total_amount <= 0 THEN 1 ELSE 0 END) as invalid_amounts
FROM silver.transactions_detailed
```

#### ğŸ”§ æŠ€è¡“çš„æœ€é©åŒ–
**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šæ‰‹æ³•**:
- Z-Orderæœ€é©åŒ–ã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒªé«˜é€ŸåŒ–
- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ï¼ˆå¹´æœˆåˆ¥ï¼‰
- Delta Lake Time Travelã«ã‚ˆã‚‹å¤‰æ›´å±¥æ­´ç®¡ç†
- Auto Compactionã«ã‚ˆã‚‹å°ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ
- Bloom Filterã«ã‚ˆã‚‹æ¤œç´¢æœ€é©åŒ–

**ç›£è¦–ãƒ»é‹ç”¨**:
- Delta Lake ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–
- ã‚¸ãƒ§ãƒ–å®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®è¿½è·¡
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°åˆ†æã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
- ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡æœ€é©åŒ–

### ğŸ“ [03_Databricks demo for beginner](./03_Databricks%20demo%20for%20beginner/) - åˆå¿ƒè€…å‘ã‘ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
**ãƒ¬ãƒ™ãƒ«**: åˆç´š | **æ‰€è¦æ™‚é–“**: 1-2æ™‚é–“

Databricksåˆå¿ƒè€…å‘ã‘ã®åŸºæœ¬æ“ä½œç¿’å¾—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

**å­¦ç¿’å†…å®¹:**
- Databricksã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ä½œæˆãƒ»ç®¡ç†
- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®åŸºæœ¬æ“ä½œ
- SQLã¨Pythonã®åŸºæœ¬çš„ãªä½¿ã„æ–¹
- æ©Ÿæ¢°å­¦ç¿’ï¼ˆAutoMLï¼‰ã®åŸºç¤

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:**
- Databricks Community Editionå¯¾å¿œ
- Spark SQL
- Pandas
- Scikit-learn
- AutoML

### â˜ï¸ [04_ykoide_AWS_EndToEnd_withUC_v2](./04_ykoide_AWS_EndToEnd_withUC_v2/) - AWSçµ±åˆã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰
**ãƒ¬ãƒ™ãƒ«**: ä¸Šç´š | **æ‰€è¦æ™‚é–“**: 6-8æ™‚é–“

AWSã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆã«ã‚ˆã‚‹ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒ‡ãƒ¼ã‚¿ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

**å­¦ç¿’å†…å®¹:**
- Unity Catalogã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¬ãƒãƒŠãƒ³ã‚¹
- AWSã‚µãƒ¼ãƒ“ã‚¹ï¼ˆS3, IAMç­‰ï¼‰ã¨ã®é€£æº
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- MLOpsã¨ãƒ¢ãƒ‡ãƒ«ç®¡ç†

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:**
- Databricks on AWS
- Unity Catalog
- MLflow
- AWS S3/IAM
- Databricks Asset Bundles

### ğŸŒŠ [05_DE_End2End_withDLT_v3](./05_DE_End2End_withDLT_v3/) - Delta Live Tables
**ãƒ¬ãƒ™ãƒ«**: ä¸Šç´š | **æ‰€è¦æ™‚é–“**: 4-6æ™‚é–“

Delta Live Tablesã‚’æ´»ç”¨ã—ãŸå®£è¨€çš„ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**å­¦ç¿’å†…å®¹:**
- Delta Live Tables (DLT)ã«ã‚ˆã‚‹å®£è¨€çš„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã¨Expectations
- ç¶™ç¶šçš„ãƒ‡ãƒ¼ã‚¿é…ä¿¡
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç›£è¦–ã¨é‹ç”¨

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:**
- Delta Live Tables
- Databricks Workflows
- Data Quality Monitoring
- Unity Catalog

## ğŸ¯ å­¦ç¿’ãƒ‘ã‚¹

### ğŸ“š æ¨å¥¨å­¦ç¿’é †åº

1. **ãƒ‡ãƒ¼ã‚¿åˆ†æå…¥é–€**
   ```
   03_Databricks demo for beginner â†’ 01_yukiteru_mart
   ```

2. **ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ç¿’å¾—**
   ```
   02_yukiterumart_ETL â†’ 05_DE_End2End_withDLT_v3
   ```

3. **ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå®Ÿè£…**
   ```
   04_ykoide_AWS_EndToEnd_withUC_v2
   ```

### ğŸ› ï¸ ç¿’å¾—æŠ€è¡“ãƒãƒƒãƒ—

| ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | SQL | Python | Spark | Delta | AutoML | DLT | Unity Catalog | AWS |
|-------------|-----|--------|-------|-------|--------|-----|---------------|-----|
| 01_yukiteru_mart | âœ… | â­ | â­ | âœ… | âŒ | âŒ | â­ | âŒ |
| 02_yukiterumart_ETL | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | â­ | âŒ |
| 03_beginner | âœ… | âœ… | â­ | â­ | âœ… | âŒ | âŒ | âŒ |
| 04_AWS_EndToEnd | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… | âœ… |
| 05_DLT | âœ… | âœ… | âœ… | âœ… | â­ | âœ… | âœ… | â­ |

**å‡¡ä¾‹**: âœ… é‡ç‚¹ç¿’å¾— | â­ è»½ãä½¿ç”¨ | âŒ ä½¿ç”¨ã—ãªã„

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### å‰ææ¡ä»¶
- Databricksã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼ˆCommunity Editionã§ã‚‚å¯ï¼‰
- åŸºæœ¬çš„ãªSQLçŸ¥è­˜
- Pythonã®åŸºæœ¬çš„ãªçŸ¥è­˜ï¼ˆæ¨å¥¨ï¼‰

### ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
1. **Databricksãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®ä½œæˆ**
   - [Databricks Community Edition](https://community.cloud.databricks.com/) ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ
   - ã¾ãŸã¯ä¼æ¥­ç‰ˆDatabricksã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©å–å¾—

2. **ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ä½œæˆ**
   ```
   - ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å: learning-cluster
   - Runtime: LTS (æœ€æ–°ç‰ˆæ¨å¥¨)
   - ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: å°ã€œä¸­è¦æ¨¡ (å­¦ç¿’ç”¨)
   ```

3. **ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ**
   - å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’Databricksã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
   - READMEãƒ•ã‚¡ã‚¤ãƒ«ã®æ‰‹é †ã«å¾“ã£ã¦å®Ÿè¡Œ

## ğŸ“– å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°

### ãƒ“ã‚¸ãƒã‚¹ã‚·ãƒŠãƒªã‚ª
å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ŒYukiteru Martã€ã¨ã„ã†æ¶ç©ºã®å°å£²ãƒã‚§ãƒ¼ãƒ³ã‚’é¡Œæã«ã—ã¦ãŠã‚Šã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã„ã¾ã™ï¼š

- **é¡§å®¢ãƒ‡ãƒ¼ã‚¿**: å¹´é½¢ã€æ€§åˆ¥ã€ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«
- **å•†å“ãƒ‡ãƒ¼ã‚¿**: ã‚«ãƒ†ã‚´ãƒªã€ä¾¡æ ¼ã€åœ¨åº«æƒ…å ±
- **åº—èˆ—ãƒ‡ãƒ¼ã‚¿**: ç«‹åœ°ã€ç®¡ç†è€…ã€å–¶æ¥­æ™‚é–“
- **å£²ä¸Šãƒ‡ãƒ¼ã‚¿**: å–å¼•å±¥æ­´ã€è³¼å…¥æ•°é‡ã€æ—¥æ™‚
- **ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿**: å•†å“è©•ä¾¡ã€é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯

### å®Ÿç¾ã§ãã‚‹åˆ†æ
- ğŸ“Š **å£²ä¸Šåˆ†æ**: åº—èˆ—åˆ¥ãƒ»å•†å“åˆ¥ãƒ»æ™‚ç³»åˆ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- ğŸ‘¥ **é¡§å®¢åˆ†æ**: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€LTVã€ãƒãƒ£ãƒ¼ãƒ³äºˆæ¸¬
- ğŸª **åº—èˆ—åˆ†æ**: ç«‹åœ°åŠ¹æœã€é‹å–¶åŠ¹ç‡ã€æ¯”è¼ƒåˆ†æ
- â­ **å•†å“åˆ†æ**: å£²ä¸Švsè©•ä¾¡ã€åœ¨åº«æœ€é©åŒ–

## ğŸ”§ æŠ€è¡“è©³ç´°

### Databricksã‚³ã‚¢æ©Ÿèƒ½
- **Unity Catalog**: ãƒ‡ãƒ¼ã‚¿ã‚¬ãƒãƒŠãƒ³ã‚¹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- **Delta Lake**: ACIDæº–æ‹ ã®ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¯
- **Auto Loader**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿
- **MLflow**: æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†
- **Workflows**: ã‚¸ãƒ§ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨è‡ªå‹•åŒ–

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³
- **ãƒ¡ãƒ€ãƒªã‚ªãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Bronze â†’ Silver â†’ Gold
- **Lambda Architecture**: ãƒãƒƒãƒ + ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
- **ãƒ‡ãƒ¼ã‚¿ãƒ¡ãƒƒã‚·ãƒ¥**: åˆ†æ•£ãƒ‡ãƒ¼ã‚¿æ‰€æœ‰æ¨©
- **ãƒ¬ã‚¤ã‚¯ãƒã‚¦ã‚¹**: ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¯ + ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹

## ğŸ“ å­¦ç¿’æˆæœ

### åˆç´šãƒ¬ãƒ™ãƒ«å®Œäº†å¾Œ
- Databricksã®åŸºæœ¬æ“ä½œã‚’ãƒã‚¹ã‚¿ãƒ¼
- SQLã¨Pythonã§ã®ãƒ‡ãƒ¼ã‚¿æ“ä½œ
- åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
- ç°¡å˜ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆ

### ä¸­ç´šãƒ¬ãƒ™ãƒ«å®Œäº†å¾Œ
- ETLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆãƒ»å®Ÿè£…
- Delta Lakeã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- ãƒ¡ãƒ€ãƒªã‚ªãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç†è§£
- ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã®å®Ÿè£…

### ä¸Šç´šãƒ¬ãƒ™ãƒ«å®Œäº†å¾Œ
- ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒ‡ãƒ¼ã‚¿ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³è¨­è¨ˆ
- Unity Catalogã«ã‚ˆã‚‹ã‚¬ãƒãƒŠãƒ³ã‚¹å®Ÿè£…
- AWSã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆ
- Delta Live Tablesã«ã‚ˆã‚‹å®£è¨€çš„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- MLOpsã¨ãƒ¢ãƒ‡ãƒ«é‹ç”¨

## ğŸ¤ è²¢çŒ®ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯

### æ”¹å–„ææ¡ˆ
- Issueä½œæˆã«ã‚ˆã‚‹ãƒã‚°å ±å‘Šãƒ»æ©Ÿèƒ½è¦æœ›
- Pull Requestã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰æ”¹å–„
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

### è³ªå•ãƒ»ã‚µãƒãƒ¼ãƒˆ
- å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®READMEã‚’ç¢ºèª
- GitHub Discussionsã§ã®è³ªå•
- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã®æ´»ç”¨

## ğŸ“š é–¢é€£ãƒªã‚½ãƒ¼ã‚¹

### å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [Databricks Documentation](https://docs.databricks.com/)
- [Delta Lake Documentation](https://docs.delta.io/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)

### å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹
- [Databricks Academy](https://academy.databricks.com/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Unity Catalog Best Practices](https://docs.databricks.com/data-governance/unity-catalog/index.html)

### ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
- [Databricks Community Forum](https://community.databricks.com/)
- [Stack Overflow - Databricks](https://stackoverflow.com/questions/tagged/databricks)

---

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯æ•™è‚²ç›®çš„ã§ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯è‡ªç”±ã«ä½¿ç”¨ãƒ»æ”¹å¤‰ã§ãã¾ã™ãŒã€å•†ç”¨åˆ©ç”¨æ™‚ã¯é©åˆ‡ãªå¸°å±è¡¨ç¤ºã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚

## ğŸ·ï¸ ã‚¿ã‚°

`#Databricks` `#DataEngineering` `#DataAnalytics` `#ETL` `#DeltaLake` `#MachineLearning` `#BigData` `#CloudComputing` `#Tutorial` `#HandsOn` 